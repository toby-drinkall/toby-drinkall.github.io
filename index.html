<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Tobias Drinkall</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Tobias Drinkall – research scientist working on AI alignment, military decision-support systems, and the ethics of AI in defence.">
  <link href="style.css" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=EB+Garamond&family=Inter&display=swap" rel="stylesheet">
  <link rel="icon" type="image/png" href="favicon.png">
</head>
<body>
  <header class="header-flex">
    <img src="tobias_drinkall.jpeg" alt="Tobias Drinkall" class="profile-pic-small">
    <div class="header-text">
      <h1>Tobias Drinkall</h1>
      <p>Research Scientist · AI Alignment, Defence, Policy & Communication</p>
    </div>
  </header>

  <nav class="nav">
    <a href="#about">About</a>
    <a href="#publications">Publications</a>
    <a href="#projects">Projects</a>
    <a href="#cv">CV</a>
    <a href="#contact">Contact</a>
  </nav>

  <main>
    <section id="about">
      <h2>About</h2>
      <p>
        I’m a research scientist interested in machine learning, interpretability, and the ethics of AI in high-stakes systems. I’m currently completing my MSc at the University of Oxford, where my thesis explores strategic creativity in military decision-support systems and the alignment of autonomous systems with human ethical values.
      </p>
      <p>
        Alongside my thesis, I work as a Research Assistant at the Oxford Internet Institute and the Alan Turing Institute under Professor Mariarosaria Taddeo. My research contributes to the <em>Ethics of AI in Defence</em> project.
      </p>
      <p>
        I also serve as a Senior Fellow and Team Lead in the Next Frontier Seminar — a transatlantic fellowship funded by Eric Schmidt — where I lead Oxford’s team in developing the first benchmarks for evaluating LLMs’ adherence to International Humanitarian Law. This work sits at the intersection of frontier AI, interpretability, and responsible deployment.
      </p>
    </section>
    
    <section id="publications">
      <h2>Publications & Writing</h2>
      <ul class="card-list">
        <li class="card">
          <h3>Quantifying Legal Risks from Language Models in Military Decision-Making</h3>
          <p class="meta">2025 · Simulation-based evaluation of LLMs for IHL compliance in high-stakes military planning.</p>
          <p class="links">
            <a href="#" target="_blank" rel="noopener">PDF (coming soon)</a>
            <span>·</span>
            <a href="#" target="_blank" rel="noopener">Code</a>
          </p>
        </li>
        <li class="card">
          <h3>Delegated Doctrine: How Military AI Risks Outsourcing the Moral Logic of War</h3>
          <p class="meta">Essay · On the strategic and ethical risks of LLM-powered decision-support systems in defence.</p>
          <p class="links">
            <a href="#" target="_blank" rel="noopener">Draft</a>
          </p>
        </li>
        <!-- Add more items as you publish things -->
      </ul>
    </section>

    <section id="projects">
      <h2>Projects</h2>
      <ul class="card-list">
        <li class="card">
          <h3>Ethics of AI in Defence</h3>
          <p class="meta">Oxford Internet Institute · Alan Turing Institute</p>
          <p>
            Contributing to research on ethical frameworks for AI-based military decision-support systems, focusing on accountability, interpretability, and meaningful human control.
          </p>
        </li>
        <li class="card">
          <h3>LLM IHL Benchmarking</h3>
          <p class="meta">Next Frontier Seminar · Senior Fellow & Team Lead</p>
          <p>
            Leading Oxford’s team in developing the first evaluation suite for open-source language models’ adherence to International Humanitarian Law, using multi-agent wargaming simulations.
          </p>
          <p class="links">
            <a href="#" target="_blank" rel="noopener">Project overview</a>
            <span>·</span>
            <a href="#" target="_blank" rel="noopener">GitHub</a>
          </p>
        </li>
        <li class="card">
          <h3>MSc Thesis: Strategic Creativity in Human–AI Collaboration</h3>
          <p class="meta">University of Oxford · MSc Social Science of the Internet</p>
          <p>
            Exploring how autonomous systems reason under adversarial conditions and how human–AI collaboration can be structured to preserve strategic creativity and normative alignment.
          </p>
        </li>
      </ul>
    </section>

    <section id="cv">
      <h2>CV</h2>
      <p>
        For a full overview of my academic background, research, and professional experience:
      </p>
      <p>
        <a class="cv-button" href="Tobias_Drinkall_CV.pdf" target="_blank" rel="noopener">
          Download CV (PDF)
        </a>
      </p>
    </section>

    <section id="contact" class="contact">
      <h2>Contact</h2>
      <p>
        <a href="https://github.com/toby-drinkall" target="_blank" rel="noopener">GitHub</a> •
        <a href="https://www.linkedin.com/in/toby-drinkall-76aa75197/" target="_blank" rel="noopener">LinkedIn</a> •
        <a href="mailto:toby.drinkall@gmail.com">Email</a>
      </p>
    </section>
  </main>
</body>
</html>

