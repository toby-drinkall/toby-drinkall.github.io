<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Tobias Drinkall</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="style.css" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=EB+Garamond&family=Inter&display=swap" rel="stylesheet">
  <link rel="icon" type="image/png" href="favicon.png">
</head>
<body>
  <header class="header-flex">
    <img src="tobias_drinkall.jpeg" alt="Tobias Drinkall" class="profile-pic-small">
    <div class="header-text">
      <h1>Toby Drinkall</h1>
      <p>AI & Data Science · Oxford</p>
      <p class="header-links">
        <a href="#about">About</a> ·
        <a href="#projects">Projects</a> ·
        <a href="#writing">Writing</a> ·
        <a href="#testimonials">Testimonials</a> ·
        <a href="#contact">Contact</a>
      </p>
    </div>
  </header>

  <main>
    <!-- About -->
    <section id="about">
      <h2>About</h2>
      <p>
        I’m a research scientist interested in machine learning, interpretability, and the ethics of AI in high-stakes systems.
        I’m currently completing my MSc at the University of Oxford, where my thesis explores strategic creativity in military
        decision-support systems and the alignment of autonomous systems with human ethical values.
      </p>
      <p>
        Alongside my thesis, I work as a Research Assistant at the Oxford Internet Institute and the Alan Turing Institute
        under Professor Mariarosaria Taddeo. My research contributes to the <em>Ethics of AI in Defence</em> project.
      </p>
      <p>
        I also serve as a Senior Fellow and Team Lead in the Next Frontier Seminar — a transatlantic fellowship funded by Eric Schmidt —
        where I lead Oxford’s team in developing the first benchmarks for evaluating LLMs’ adherence to International Humanitarian Law.
        This work sits at the intersection of frontier AI, interpretability, and responsible deployment.
      </p>

      <!-- Highlight rectangle with four sections -->
      <div class="summary-grid">
        <div class="summary-item">
          <h3>Degree</h3>
          <p>
            <strong>Oxford, MS Data Science (Distinction)</strong><br>
            Quantiative Data Science; Cyrptography; Machine learning; Statistics. Built and published LLM agent evals for military decision-suport systems
          </p>
          <p>
            <strong>Oxford, BA Theology (First Class)</strong><br>
            19th-century philosophy; theory of mind; Eastern Christianity; Anglican ecclesiology.
          </p>
        </div>
        <div class="summary-item">
          <h3>Fellowships</h3>
          <p>
            Senior Fellow & Team Lead, Next Frontier Seminar (AI & National Security).<br>
            Work spans LLM evaluation, IHL compliance, and strategic risk analysis.
          </p>
        </div>
        <div class="summary-item">
          <h3>Judging</h3>
          <p>
            Reviewer and judge for AI safety and alignment initiatives, hackathons, and research competitions focused on
            high-stakes deployment and responsible AI.
          </p>
        </div>
        <div class="summary-item">
          <h3>Conferences</h3>
          <p>
            Talks and workshops delivered at institutions including Stanford’s Hoover Institution, NATO-affiliated events,
            Oxford, and policy forums in Washington, D.C. and Europe.
          </p>
        </div>
      </div>
    </section>

    <!-- Projects -->
    <section id="projects">
      <h2>Projects</h2>
      <ul class="card-list">
        <li class="card">
          <h3>LLM IHL Benchmarking</h3>
          <p class="meta">Next Frontier Seminar · Senior Fellow & Team Lead</p>
          <p>
            Developing a simulation-based evaluation suite for language models, measuring their adherence to
            International Humanitarian Law in conflict scenarios, with metrics for escalation and civilian harm.
          </p>
        </li>
        <li class="card">
          <h3>Ethics of AI in Defence</h3>
          <p class="meta">Oxford Internet Institute · Alan Turing Institute</p>
          <p>
            Researching ethical frameworks and governance models for AI-enabled military decision-support systems, with
            a focus on meaningful human control, accountability, and transparency.
          </p>
        </li>
        <li class="card">
          <h3>MSc Thesis: Strategic Creativity in Human–AI Collaboration</h3>
          <p class="meta">University of Oxford</p>
          <p>
            Exploring how AI systems shape strategic reasoning in adversarial settings, and how human–AI teams can be
            structured to preserve creativity, normative alignment, and robust oversight.
          </p>
        </li>
      </ul>
    </section>

    <!-- Writing -->
    <section id="writing">
      <h2>Writing</h2>
      <ul class="writing-list">
        <li>
          <strong>
            <a href="quantifying-legal-risks.html">
              Quantifying Legal Risks from Language Models in Military Decision-Making
            </a>
          </strong>
          – Simulation-based evaluation of LLMs for IHL compliance in high-stakes military planning.
        </li>
        <li>
          <strong>
            <a href="delegated-doctrine.html">
              Delegated Doctrine: How Military AI Risks Outsourcing the Moral Logic of War
            </a>
          </strong>
          – Essay on the strategic and ethical risks of LLM-powered decision-support systems in defence.
        </li>
        <li>
          <strong>
            <a href="msc-thesis.html">
              MSc Thesis: Strategic Creativity in Human–AI Collaboration
            </a>
          </strong>
          – Ongoing work on how AI decision-support systems shape strategic reasoning in adversarial environments.
        </li>
      </ul>
    </section>

    <!-- Testimonials -->
    <section id="testimonials" class="testimonials">
      <h2>Testimonials</h2>
      <div class="testimonial-list">
        <figure class="testimonial">
          <blockquote>
            “Tobias combines technical depth with an unusual ability to communicate complex ideas clearly to both
            technical and policy audiences.”
          </blockquote>
          <figcaption>Senior researcher in AI ethics & defence</figcaption>
        </figure>

        <figure class="testimonial">
          <blockquote>
            “His work on evaluating LLMs in military wargaming has been instrumental in shaping how we think about
            responsible deployment in high-stakes environments.”
          </blockquote>
          <figcaption>National security fellow & project collaborator</figcaption>
        </figure>

        <figure class="testimonial">
          <blockquote>
            “Tobias is rare in that he is comfortable writing, coding, and presenting at a very high level – and can
            connect these skills directly to real-world decisions.”
          </blockquote>
          <figcaption>Industry partner in AI strategy</figcaption>
        </figure>
      </div>
    </section>

    <!-- Contact -->
    <section id="contact" class="contact">
      <h2>Contact</h2>
      <p>
        <a href="https://github.com/toby-drinkall" target="_blank" rel="noopener">GitHub</a> ·
        <a href="https://www.linkedin.com/in/toby-drinkall-76aa75197/" target="_blank" rel="noopener">LinkedIn</a> ·
        <a href="mailto:toby.drinkall@gmail.com">Email</a>
      </p>
    </section>
  </main>
</body>
</html>
