<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Tobias Drinkall</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="style.css" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=EB+Garamond&family=Inter&display=swap" rel="stylesheet">
  <link rel="icon" type="image/png" href="favicon.png">
</head>
<body>
  <header class="header-flex">
    <img src="tobias_drinkall.jpeg" alt="Tobias Drinkall" class="profile-pic-small">
    <div class="header-text">
      <h1>Tobias Drinkall</h1>
      <p>Research Scientist · AI Alignment, Defence, Policy & Communication</p>
      <p>
        <a href="#bio">Bio</a> ·
        <a href="#writing">My Writing</a> ·
        <a href="#contact">Contact</a>
      </p>
    </div>
  </header>

  <main>
    <section id="bio">
      <h2>Bio</h2>
      <p>
        I’m a research scientist interested in machine learning, interpretability, and the ethics of AI in high-stakes systems.
        I’m currently completing my MSc at the University of Oxford, where my thesis explores strategic creativity in military
        decision-support systems and the alignment of autonomous systems with human ethical values.
      </p>
      <p>
        Alongside my thesis, I work as a Research Assistant at the Oxford Internet Institute and the Alan Turing Institute
        under Professor Mariarosaria Taddeo. My research contributes to the <em>Ethics of AI in Defence</em> project.
      </p>
      <p>
        I also serve as a Senior Fellow and Team Lead in the Next Frontier Seminar — a transatlantic fellowship funded by Eric Schmidt —
        where I lead Oxford’s team in developing the first benchmarks for evaluating LLMs’ adherence to International Humanitarian Law.
        This work sits at the intersection of frontier AI, interpretability, and responsible deployment.
      </p>
    </section>

    <section id="writing">
      <h2>My Writing</h2>
      <ul>
        <li>
          <strong>
            <a href="quantifying-legal-risks.html">
              Quantifying Legal Risks from Language Models in Military Decision-Making
            </a>
          </strong>
          – Simulation-based evaluation of LLMs for IHL compliance in high-stakes military planning.
        </li>
        <li>
          <strong>
            <a href="delegated-doctrine.html">
              Delegated Doctrine: How Military AI Risks Outsourcing the Moral Logic of War
            </a>
          </strong>
          – Essay on the strategic and ethical risks of LLM-powered decision-support systems in defence.
        </li>
        <li>
          <strong>
            <a href="msc-thesis.html">
              MSc Thesis: Strategic Creativity in Human–AI Collaboration
            </a>
          </strong>
          – Ongoing work on how AI decision-support systems shape strategic reasoning in adversarial environments.
        </li>
        <!-- Add or remove items as you create more pages -->
      </ul>
    </section>

    <section id="contact" class="contact">
      <h2>Contact</h2>
      <p>
        <a href="https://github.com/toby-drinkall" target="_blank" rel="noopener">GitHub</a> ·
        <a href="https://www.linkedin.com/in/toby-drinkall-76aa75197/" target="_blank" rel="noopener">LinkedIn</a> ·
        <a href="mailto:toby.drinkall@gmail.com">Email</a>
      </p>
    </section>
  </main>
</body>
</html>
